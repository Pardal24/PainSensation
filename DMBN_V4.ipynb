{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2142326/3118407570.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display as html_width\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.layers import Add,Multiply,Softmax,Input,TimeDistributed,Dense,Average,GlobalAveragePooling1D,Concatenate,Lambda,RepeatVector, Conv2D,ConvLSTM2D, MaxPooling2D,BatchNormalization,Flatten,Reshape,UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "html_width(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import psutil\n",
    "import pickle\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n",
      "2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 19:36:44.800479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-17 19:36:44.800643: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 20  6 38 21 33  5 15 47 13  1  2 34 10 16 25 39 27  3 41 31 23 49 36\n",
      " 18 29  0 43 22  9 28  7 46 24 12 14 26  4 32 11 45 48 37 40 17  8 44 19\n",
      " 42 30]\n",
      "Remaining train_p: [13, 1, 2, 10, 16, 25, 39, 27, 3, 41, 31, 23, 49, 36, 18, 29, 0, 43, 22, 9, 28, 7, 46, 24, 12, 14, 26, 4, 32, 11, 45, 48, 37, 40, 17, 8, 44, 19, 42, 30]\n",
      "test_p: [35, 20, 6, 38, 21, 33, 5, 15, 47, 34]\n"
     ]
    }
   ],
   "source": [
    "obs_min = 4\n",
    "obs_max = 8\n",
    "train_N = 49\n",
    "train_p = np.random.permutation(50)\n",
    "j = 0\n",
    "x = 0\n",
    "test_p = []\n",
    "valid_p = []\n",
    "print(train_p)\n",
    "\n",
    "train_p_copy = train_p.copy()\n",
    "\n",
    "for i in train_p_copy:\n",
    "    if i <= 24 and j < 5:\n",
    "        test_p.append(i)\n",
    "        j += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "    if i > 24 and x < 5:\n",
    "        test_p.append(i)\n",
    "        x += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "\n",
    "print(\"Remaining train_p:\", train_p)\n",
    "print(\"test_p:\", test_p)\n",
    "\n",
    "# j = 0\n",
    "# x = 0\n",
    "# test_p_copy = test_p.copy()\n",
    "# for i in test_p_copy:\n",
    "#     if i < 25 and j < 3:\n",
    "#         valid_p.append(i)\n",
    "#         j += 1\n",
    "#         test_p = [item for item in test_p if item != i]\n",
    "#     if i > 25 and x < 2:\n",
    "#         valid_p.append(i)\n",
    "#         x += 1\n",
    "#         test_p = [item for item in test_p if item != i] \n",
    "# print(\"valid_p:\", valid_p)\n",
    "# print(\"test_p:\", test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Modality Blending Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try now with only 2 inputs (img and touch)\n",
    "\n",
    "rndm coef like default\n",
    "\n",
    "if more worried about the image using a coef for the image >0.2\n",
    "\n",
    "For testing give 1 to img coef for only giving image\n",
    "\n",
    "For easy test give coef of 0.5 for only two inputs\n",
    "\n",
    "always add rnd samples from 0 zone and touch zone if necessary\n",
    "\n",
    "plot the touch.txt for each data folder\n",
    "\n",
    "use the weights from default\n",
    "\n",
    "Add noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coef > 2\n",
    "noise\n",
    "plot for only one sensor\n",
    "reduce/increase more the weight for the touch sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################### GET TRAIN SAMPLES ############################################################################\n",
    "\n",
    "def get_train_sample(coef = -1):\n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = train_p[np.random.randint(0, 39)]\n",
    "    \n",
    "    if coef == -1:\n",
    "         coef = np.random.uniform(0.2, 1.0)\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    selected_indices = np.random.permutation(time_len)\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, i, :, :, 1:] = image_resized\n",
    "            #print(observation[0, i, :, :, 1:])\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = pose[idx] / 255\n",
    "\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    #print(target_X)\n",
    "    t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize \n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    # i=2\n",
    "    # display.clear_output(wait=True)\n",
    "    # display.display(pl.gcf())\n",
    "    # plt.imshow(target_Y[0,:,:,:3] * 255)\n",
    "    # plt.show()\n",
    "    #print (target_Y)\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1], coef\n",
    "\n",
    "#inp, out, _, _, _ = get_train_sample()\n",
    "# print(out)\n",
    "\n",
    "######################################################################### GET VALIDATION SAMPLES ############################################################################\n",
    "\n",
    "\n",
    "def get_valid_sample(): \n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = valid_p[np.random.randint(0, 4)]\n",
    "\n",
    "    coef = 1\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    # Identify zero and nonzero rows\n",
    "    zero_rows = np.where(np.all(pose == 0, axis=1))[0]\n",
    "    nonzero_rows = np.where(np.any(pose != 0, axis=1))[0]\n",
    "    \n",
    "    if len(nonzero_rows) == 0 or len(zero_rows) == 0:\n",
    "        raise ValueError(\"Dataset does not contain both zero and nonzero rows.\")\n",
    "\n",
    "    # Ensure at least one sample from each\n",
    "    num_from_each = min(n // 2, len(nonzero_rows), len(zero_rows))\n",
    "    selected_nonzero = np.random.choice(nonzero_rows, num_from_each, replace=False)\n",
    "    selected_zero = np.random.choice(zero_rows, num_from_each, replace=False)\n",
    "\n",
    "    remaining_samples = n - 2 * num_from_each\n",
    "    if remaining_samples > 0:\n",
    "        additional_samples = np.random.choice(time_len, remaining_samples, replace=False)\n",
    "    else:\n",
    "        additional_samples = np.array([], dtype=int)\n",
    "    selected_indices = np.concatenate((selected_nonzero, selected_zero, additional_samples))\n",
    "    np.random.shuffle(selected_indices)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, i, :, :, 1:] = image_resized / 255\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = pose[idx] / 255\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize / 255.\n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1]\n",
    "\n",
    "\n",
    "########################################################################## GET TEST SAMPLES ####################################################################################\n",
    "\n",
    "\n",
    "def get_test_sample(t,n, size):\n",
    "    d = test_p[t]\n",
    "    out = []\n",
    "    #print(d)\n",
    "    coef = 1\n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "\n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "\n",
    "    for idx in range(size):\n",
    "        if idx < n:\n",
    "            observation[0, idx, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, idx, :, :, 1:] = image_resized \n",
    "            target_Y[0, :, :, :3] = image_resized \n",
    "\n",
    "            observation_touch[0, idx, 0] = times[idx]\n",
    "            observation_touch[0, idx, 1:9] = pose[idx] / 255\n",
    "            target_Y_touch[0, :8] = pose[idx] / 255\n",
    "        else:\n",
    "            t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "            target_Y[0, :, :, :3] = t_img_resize \n",
    "            target_Y_touch[0, :8] = pose[idx] / 255\n",
    "        out.append([target_Y.copy(), target_Y_touch.copy()])\n",
    "\n",
    "    target_X[0, 0] = times[n]\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], out, idx, times\n",
    "\n",
    "#inp, out, x, clock = get_test_sample(1,5,55)\n",
    "#print(out[44][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(y_true, y_predicted):\n",
    "    mean, log_sigma = tf.split(y_predicted, 2, axis=-1)\n",
    "    y_true_value, temp =tf.split(y_true,2,axis=-1)\n",
    "    #mean = tf.nn.relu(mean)\n",
    "    sigma = tf.nn.softplus(log_sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(loc=mean, scale_diag=sigma)\n",
    "    loss = -tf.reduce_mean(dist.log_prob(y_true_value))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_observation (InputLa  [(None, None, 128, 128, 4)   0         []                            \n",
      " yer)                        ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDi  (None, None, 128, 128, 32)   1184      ['image_observation[0][0]']   \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDi  (None, None, 64, 64, 32)     0         ['time_distributed_7[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDi  (None, None, 64, 64, 64)     18496     ['time_distributed_8[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeD  (None, None, 32, 32, 64)     0         ['time_distributed_9[0][0]']  \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeD  (None, None, 32, 32, 64)     36928     ['time_distributed_10[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeD  (None, None, 16, 16, 64)     0         ['time_distributed_11[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " touch_observation (InputLa  [(None, None, 9)]            0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeD  (None, None, 16, 16, 128)    73856     ['time_distributed_12[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 32)             320       ['touch_observation[0][0]']   \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeD  (None, None, 8, 8, 128)      0         ['time_distributed_13[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, None, 64)             2112      ['time_distributed[0][0]']    \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_15 (TimeD  (None, None, 8, 8, 128)      147584    ['time_distributed_14[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, None, 64)             4160      ['time_distributed_1[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_16 (TimeD  (None, None, 4, 4, 128)      0         ['time_distributed_15[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDi  (None, None, 128)            8320      ['time_distributed_2[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_17 (TimeD  (None, None, 4, 4, 256)      295168    ['time_distributed_16[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDi  (None, None, 128)            16512     ['time_distributed_3[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_18 (TimeD  (None, None, 2, 2, 256)      0         ['time_distributed_17[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDi  (None, None, 256)            33024     ['time_distributed_4[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_19 (TimeD  (None, None, 1024)           0         ['time_distributed_18[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDi  (None, None, 128)            32896     ['time_distributed_5[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_20 (TimeD  (None, None, 128)            131200    ['time_distributed_19[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['time_distributed_6[0][0]']  \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " touch_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['time_distributed_20[0][0]'] \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " image_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 128)                  0         ['global_average_pooling1d[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'touch_coef[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 128)                  0         ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'image_coef[0][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128)                  0         ['multiply[0][0]',            \n",
      "                                                                     'multiply_1[0][0]']          \n",
      "                                                                                                  \n",
      " target_X (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " merged (Concatenate)        (None, 129)                  0         ['add[0][0]',                 \n",
      "                                                                     'target_X[0][0]']            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1024)                 133120    ['merged[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 2, 2, 256)            0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 2, 2, 256)            590080    ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 4, 4, 256)            0         ['conv2d_6[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 128)            295040    ['up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 8, 8, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)            147584    ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_8[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)           73792     ['up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 64)           36928     ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_10[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 32)           18464     ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 512)                  524800    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 128, 128, 32)         0         ['conv2d_11[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 216)                  110808    ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 16)         4624      ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 128)                  27776     ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 8)          1160      ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 32)                   4128      ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " last_conv2d (Conv2D)        (None, 128, 128, 6)          438       ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " touch_values (Dense)        (None, 8)                    264       ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2770766 (10.57 MB)\n",
      "Trainable params: 2770766 (10.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_layer = Input(shape=(None,128,128,4), name=\"image_observation\") \n",
    "touch_layer = Input(shape=(None,9), name=\"touch_observation\") \n",
    "target_X_layer = Input(shape=(1,), name = 'target_X')\n",
    "img_coef_layer = Input(shape=(128,), name = 'image_coef')\n",
    "touch_coef_layer = Input(shape=(128,), name = 'touch_coef')\n",
    "\n",
    "encoder_touch_sizes = [64,64,128,128,256]\n",
    "\n",
    "touch_encoder = TimeDistributed(Dense(32, activation = 'relu'))(touch_layer)\n",
    "for channel_size in encoder_touch_sizes:\n",
    "    touch_encoder = TimeDistributed(Dense(channel_size, activation = 'relu'))(touch_encoder)\n",
    "\n",
    "touch_representations = TimeDistributed(Dense(128, activation='relu'))(touch_encoder) #128\n",
    "touch_representation = GlobalAveragePooling1D()(touch_representations) \n",
    "\n",
    "multiplied_touch = Multiply()([touch_representation,touch_coef_layer])\n",
    "\n",
    "###################################################\n",
    "\n",
    "encoder_img_sizes = [64,64,128,128,256]\n",
    "\n",
    "image_encoder = TimeDistributed(Conv2D(32,(3,3),padding='same',activation='relu'))(image_layer)\n",
    "image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "for channel_size in encoder_img_sizes:\n",
    "    image_encoder = TimeDistributed(Conv2D(channel_size,(3,3),padding='same',activation='relu'))(image_encoder)\n",
    "    image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "\n",
    "image_flatten = TimeDistributed(Flatten())(image_encoder)\n",
    "img_representations = TimeDistributed(Dense(128, activation='relu'))(image_flatten)\n",
    "img_representation = GlobalAveragePooling1D()(img_representations) \n",
    "\n",
    "multiplied_img = Multiply()([img_representation,img_coef_layer])\n",
    "\n",
    "general_representation = Add()([multiplied_touch,multiplied_img])\n",
    "\n",
    "merged_layer = Concatenate(axis=-1, name='merged')([general_representation,target_X_layer])\n",
    "\n",
    "decoder_representation = Dense(1024, activation='relu') (merged_layer)\n",
    "\n",
    "\" =============== Image Decoder =============== \"\n",
    "decoder_img = Reshape([2,2,256])(decoder_representation)\n",
    "decoder_img_sizes = [256,128,128,64,64,32]\n",
    "\n",
    "for channel_size in decoder_img_sizes:\n",
    "    decoder_img = Conv2D(channel_size, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "    decoder_img = UpSampling2D((2, 2))(decoder_img)\n",
    "\n",
    "img_output = Conv2D(16, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "img_output = Conv2D(8, (3,3), padding='same', activation='relu')(img_output)\n",
    "img_output = Conv2D(6, (3,3), padding='same', activation='sigmoid', name = \"last_conv2d\")(img_output)\n",
    "\" =============== Image Decoder =============== \"\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "decoder_touch = Dense(512, activation='relu')(decoder_representation)\n",
    "decoder_touch = Dense(216, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(128, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(32, activation='relu')(decoder_touch)\n",
    "touch_output = Dense(8, activation='sigmoid', name=\"touch_values\")(decoder_touch)\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "\n",
    "model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],[img_output, touch_output])\n",
    "latent_model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],general_representation)\n",
    "model.summary()\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initial_lr = 1e-4  \n",
    "# lowered_lr = 1e-5 \n",
    "\n",
    "# # Use this schedule in the optimizer\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer= Adam(lr = 1e-4),\n",
    "    loss={\n",
    "        'last_conv2d': custom_loss,  \n",
    "        'touch_values': 'mse',  \n",
    "    },\n",
    "    loss_weights={\n",
    "        'last_conv2d': 1,  \n",
    "        'touch_values': 0.01, \n",
    "    },\n",
    "    metrics={  # Add accuracy tracking\n",
    "        'touch_values': ['mae'],  # Mean Absolute Error for touch values\n",
    "    }  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"Epochs_V7\", exist_ok=True)\n",
    "\n",
    "loss_checkpoint = 1000\n",
    "plot_checkpoint = 1000\n",
    "validation_checkpoint = 1000\n",
    "validation_error = 9999999\n",
    "validation_step = -1\n",
    "max_training_step = 150000\n",
    "t_inp = 10\n",
    "data_size = 55\n",
    "n_test = 10\n",
    "\n",
    "dataset = ['image','touch']\n",
    "\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})\n",
    "\n",
    "real_output = []\n",
    "predict_output = []\n",
    "touch_value_idx = 2\n",
    "loss_history = [] \n",
    "\n",
    "for step in range(max_training_step):\n",
    "    inp, out, _, _, coef = get_train_sample()\n",
    "    #val_data, val_labels, _, _ = get_valid_sample()\n",
    "    history = model.fit(inp, out, verbose=0) \n",
    "    loss_history.append(history.history['loss'][0])  \n",
    "\n",
    "    if step % loss_checkpoint == 0 and step!= 0:\n",
    "        path = f\"Epochs_V7/Epoch{step}\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Save model using pickle\n",
    "        model.save(os.path.join(path, \"model.keras\"))\n",
    "\n",
    "        # Save loss history\n",
    "        with open(os.path.join(path, \"loss_history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(loss_history, f)\n",
    "\n",
    "        for test in range(n_test):\n",
    "            step_predictions = []\n",
    "            step_real_values = []\n",
    "            step_absolute_errors_images = []\n",
    "            step_squared_errors_images = []\n",
    "            step_absolute_errors_touch = []\n",
    "            step_squared_errors_touch = []\n",
    "\n",
    "\n",
    "            test_inp, test_out, x, times = get_test_sample(test, t_inp, data_size)\n",
    "\n",
    "\n",
    "            for i in range(t_inp+1, data_size-1):\n",
    "                inp_copy = test_inp.copy() \n",
    "                inp_copy[2] = np.array([[times[i]]])\n",
    "                pred = model.predict_on_batch(inp_copy)\n",
    "\n",
    "                step_predictions.append(pred)\n",
    "                step_real_values.append(test_out[i])\n",
    "\n",
    "\n",
    "                pred_images = np.array(pred[0])\n",
    "                pred_touch_values = np.array(pred[1])  \n",
    "\n",
    "                out_images = np.array(test_out[i][0])  \n",
    "                out_touch_values = np.array(test_out[i][1])  \n",
    "            \n",
    "                step_absolute_errors_images.append(np.abs(out_images - pred_images))  \n",
    "                step_squared_errors_images.append((out_images - pred_images) ** 2) \n",
    "\n",
    "                step_absolute_errors_touch.append(np.abs(out_touch_values - pred_touch_values)) \n",
    "                step_squared_errors_touch.append((out_touch_values - pred_touch_values) ** 2) \n",
    "\n",
    "\n",
    "            del inp_copy, pred\n",
    "    \n",
    "            with open(os.path.join(path, f\"predictions_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_predictions, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"real_values_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_real_values, f)\n",
    "    \n",
    "\n",
    "            with open(os.path.join(path, f\"absolute_errors_touch_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_absolute_errors_touch, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"squared_errors_touch_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_squared_errors_touch, f)\n",
    "\n",
    "                \n",
    "            with open(os.path.join(path, f\"absolute_errors_images_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_absolute_errors_images, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"squared_errors_images_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_squared_errors_images, f)\n",
    "\n",
    "            step_predictions.clear()\n",
    "            step_real_values.clear()\n",
    "            step_absolute_errors_images.clear()\n",
    "            step_squared_errors_images.clear()\n",
    "            step_absolute_errors_touch.clear()\n",
    "            step_squared_errors_touch.clear()\n",
    "            gc.collect()\n",
    "\n",
    "    if step % 10000 == 0 and step != 0:\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
