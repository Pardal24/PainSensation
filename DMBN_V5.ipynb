{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32425/3794690065.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display as html_width\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.layers import Add,Multiply,Softmax,Input,TimeDistributed,Dense,Average,GlobalAveragePooling1D,Concatenate,Lambda,RepeatVector, Conv2D,ConvLSTM2D, MaxPooling2D,BatchNormalization,Flatten,Reshape,UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "html_width(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import tensorflow_addons as tfa\n",
    "import psutil\n",
    "import pickle\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n",
      "2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 13:59:51.114394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-21 13:59:51.114480: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 35 32 28 19 29 40 26  1  0 16 10 45 11 43 15  6 44 20  9 18 27 14  4\n",
      " 25 13 41 47 17  5 37 22  7  3 36 39 48 38 30 21 31  2 46 49 42  8 12 23\n",
      " 24 34]\n",
      "Remaining train_p: [40, 26, 45, 11, 43, 15, 6, 44, 20, 9, 18, 27, 14, 4, 25, 13, 41, 47, 17, 5, 37, 22, 7, 3, 36, 39, 48, 38, 30, 21, 31, 2, 46, 49, 42, 8, 12, 23, 24, 34]\n",
      "test_p: [33, 35, 32, 28, 19, 29, 1, 0, 16, 10]\n"
     ]
    }
   ],
   "source": [
    "obs_min = 4\n",
    "obs_max = 8\n",
    "train_N = 49\n",
    "train_p = np.random.permutation(50)\n",
    "j = 0\n",
    "x = 0\n",
    "test_p = []\n",
    "valid_p = []\n",
    "print(train_p)\n",
    "\n",
    "train_p_copy = train_p.copy()\n",
    "\n",
    "for i in train_p_copy:\n",
    "    if i <= 24 and j < 5:\n",
    "        test_p.append(i)\n",
    "        j += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "    if i > 24 and x < 5:\n",
    "        test_p.append(i)\n",
    "        x += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "\n",
    "print(\"Remaining train_p:\", train_p)\n",
    "print(\"test_p:\", test_p)\n",
    "\n",
    "# j = 0\n",
    "# x = 0\n",
    "# test_p_copy = test_p.copy()\n",
    "# for i in test_p_copy:\n",
    "#     if i < 25 and j < 3:\n",
    "#         valid_p.append(i)\n",
    "#         j += 1\n",
    "#         test_p = [item for item in test_p if item != i]\n",
    "#     if i > 25 and x < 2:\n",
    "#         valid_p.append(i)\n",
    "#         x += 1\n",
    "#         test_p = [item for item in test_p if item != i] \n",
    "# print(\"valid_p:\", valid_p)\n",
    "# print(\"test_p:\", test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, aug_prob=0.3):\n",
    "    aug_image = image.copy()\n",
    "\n",
    "    if np.random.rand() < aug_prob:\n",
    "\n",
    "        if np.random.rand() < 0.35:\n",
    "            crop_factor = np.random.uniform(0.7, 0.9) \n",
    "            aug_image = tf.image.central_crop(aug_image, crop_factor)\n",
    "\n",
    "        aug_image = tf.image.resize(aug_image, (128, 128))\n",
    "\n",
    "        if np.random.rand() < 0.35:\n",
    "            aug_image = tf.image.random_brightness(aug_image, max_delta=0.2)\n",
    "            aug_image = tf.clip_by_value(aug_image, 0.0, 1.0)  \n",
    "\n",
    "        if np.random.rand() < 0.35:\n",
    "            angles = tf.random.uniform([], minval=-0.26, maxval=0.26) \n",
    "            aug_image = tfa.image.rotate(aug_image, angles)\n",
    "\n",
    "        if np.random.rand() < 0.35:\n",
    "            translations = tf.random.uniform([2], minval=-10, maxval=10)\n",
    "            aug_image = tfa.image.translate(aug_image, translations)\n",
    "\n",
    "        # if np.random.rand() < 0.35:\n",
    "        #     aug_image = tf.image.flip_left_right(aug_image)      \n",
    "    else:\n",
    "        aug_image = tf.image.resize(aug_image, (128, 128))\n",
    "\n",
    "    return aug_image\n",
    "\n",
    "def augment_touch_values(touch_values):\n",
    "    if np.random.rand() < 0.3:  \n",
    "        noise = np.random.normal(0, 0.005, size=touch_values.shape)  \n",
    "        touch_values[touch_values > 0] = np.clip(touch_values[touch_values > 0] + noise[touch_values > 0], 0, 1)\n",
    "    return touch_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Modality Blending Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################### GET TRAIN SAMPLES ############################################################################\n",
    "\n",
    "def get_train_sample(coef = -1):\n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = train_p[np.random.randint(0, 39)]\n",
    "    \n",
    "    if coef == -1:\n",
    "         coef = np.random.uniform(0.2, 1.0)\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    selected_indices = np.random.permutation(time_len)\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "\n",
    "\n",
    "            #image_resized = cv2.resize(image, (128, 128))\n",
    "            augmented_image = augment_image(image)\n",
    "            observation[0, i, :, :, 1:] = augmented_image\n",
    "\n",
    "            # display.clear_output(wait=True)\n",
    "            # plt.imshow(observation[0, i, :, :, 1:4])\n",
    "            # plt.axis(\"off\")\n",
    "            # plt.show()\n",
    "            #print(observation[0, i, :, :, 1:])\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = augment_touch_values(pose[idx] / 255)\n",
    "            # print(pose[idx] / 255)\n",
    "            # print(observation_touch[0, i, 1:9])\n",
    "            \n",
    "\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    #print(target_X)\n",
    "    t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize \n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    # display.clear_output(wait=True)\n",
    "    # display.display(pl.gcf())\n",
    "    # plt.imshow(target_Y[0,:,:,:3])\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    #print (target_Y)\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1], coef\n",
    "\n",
    "#inp, out, _, _, _ = get_train_sample()\n",
    "# print(out)\n",
    "\n",
    "######################################################################### GET VALIDATION SAMPLES ############################################################################\n",
    "\n",
    "\n",
    "def get_valid_sample(): \n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = valid_p[np.random.randint(0, 4)]\n",
    "\n",
    "    coef = 1\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    # Identify zero and nonzero rows\n",
    "    zero_rows = np.where(np.all(pose == 0, axis=1))[0]\n",
    "    nonzero_rows = np.where(np.any(pose != 0, axis=1))[0]\n",
    "    \n",
    "    if len(nonzero_rows) == 0 or len(zero_rows) == 0:\n",
    "        raise ValueError(\"Dataset does not contain both zero and nonzero rows.\")\n",
    "\n",
    "    # Ensure at least one sample from each\n",
    "    num_from_each = min(n // 2, len(nonzero_rows), len(zero_rows))\n",
    "    selected_nonzero = np.random.choice(nonzero_rows, num_from_each, replace=False)\n",
    "    selected_zero = np.random.choice(zero_rows, num_from_each, replace=False)\n",
    "\n",
    "    remaining_samples = n - 2 * num_from_each\n",
    "    if remaining_samples > 0:\n",
    "        additional_samples = np.random.choice(time_len, remaining_samples, replace=False)\n",
    "    else:\n",
    "        additional_samples = np.array([], dtype=int)\n",
    "    selected_indices = np.concatenate((selected_nonzero, selected_zero, additional_samples))\n",
    "    np.random.shuffle(selected_indices)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, i, :, :, 1:] = image_resized / 255\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = pose[idx] / 255\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize / 255.\n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1]\n",
    "\n",
    "\n",
    "########################################################################## GET TEST SAMPLES ####################################################################################\n",
    "\n",
    "\n",
    "def get_test_sample(t,n, size):\n",
    "    d = test_p[t]\n",
    "    out = []\n",
    "    #print(d)\n",
    "    coef = 1\n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "\n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    \n",
    "    pose = np.loadtxt('Data_Robot/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "\n",
    "    for idx in range(size):\n",
    "        if idx < n:\n",
    "            observation[0, idx, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, idx, :, :, 1:] = image_resized \n",
    "            target_Y[0, :, :, :3] = image_resized \n",
    "\n",
    "            observation_touch[0, idx, 0] = times[idx]\n",
    "            observation_touch[0, idx, 1:9] = pose[idx] / 255\n",
    "            target_Y_touch[0, :8] = pose[idx] / 255\n",
    "        else:\n",
    "            t_img = mpimg.imread('Data_Robot/%d/frame_%d.jpeg' % (d, idx))\n",
    "            t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "            target_Y[0, :, :, :3] = t_img_resize \n",
    "            target_Y_touch[0, :8] = pose[idx] / 255\n",
    "        out.append([target_Y.copy(), target_Y_touch.copy()])\n",
    "\n",
    "    target_X[0, 0] = times[n]\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], out, idx, times\n",
    "\n",
    "#inp, out, x, clock = get_test_sample(1,5,55)\n",
    "#print(out[44][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(y_true, y_predicted):\n",
    "    mean, log_sigma = tf.split(y_predicted, 2, axis=-1)\n",
    "    y_true_value, temp =tf.split(y_true,2,axis=-1)\n",
    "    #mean = tf.nn.relu(mean)\n",
    "    sigma = tf.nn.softplus(log_sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(loc=mean, scale_diag=sigma)\n",
    "    loss = -tf.reduce_mean(dist.log_prob(y_true_value))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_observation (InputLa  [(None, None, 128, 128, 4)   0         []                            \n",
      " yer)                        ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_28 (TimeD  (None, None, 128, 128, 32)   1184      ['image_observation[0][0]']   \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_29 (TimeD  (None, None, 64, 64, 32)     0         ['time_distributed_28[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_30 (TimeD  (None, None, 64, 64, 64)     18496     ['time_distributed_29[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_31 (TimeD  (None, None, 32, 32, 64)     0         ['time_distributed_30[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_32 (TimeD  (None, None, 32, 32, 64)     36928     ['time_distributed_31[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_33 (TimeD  (None, None, 16, 16, 64)     0         ['time_distributed_32[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " touch_observation (InputLa  [(None, None, 9)]            0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_34 (TimeD  (None, None, 16, 16, 128)    73856     ['time_distributed_33[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_21 (TimeD  (None, None, 32)             320       ['touch_observation[0][0]']   \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_35 (TimeD  (None, None, 8, 8, 128)      0         ['time_distributed_34[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_22 (TimeD  (None, None, 64)             2112      ['time_distributed_21[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_36 (TimeD  (None, None, 8, 8, 128)      147584    ['time_distributed_35[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_23 (TimeD  (None, None, 64)             4160      ['time_distributed_22[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_37 (TimeD  (None, None, 4, 4, 128)      0         ['time_distributed_36[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_24 (TimeD  (None, None, 128)            8320      ['time_distributed_23[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_38 (TimeD  (None, None, 4, 4, 256)      295168    ['time_distributed_37[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_25 (TimeD  (None, None, 128)            16512     ['time_distributed_24[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_39 (TimeD  (None, None, 2, 2, 256)      0         ['time_distributed_38[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_26 (TimeD  (None, None, 256)            33024     ['time_distributed_25[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_40 (TimeD  (None, None, 1024)           0         ['time_distributed_39[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_27 (TimeD  (None, None, 128)            32896     ['time_distributed_26[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_41 (TimeD  (None, None, 128)            131200    ['time_distributed_40[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['time_distributed_27[0][0]'] \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " touch_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3  (None, 128)                  0         ['time_distributed_41[0][0]'] \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " image_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 128)                  0         ['global_average_pooling1d_2[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'touch_coef[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 128)                  0         ['global_average_pooling1d_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'image_coef[0][0]']          \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 128)                  0         ['multiply_2[0][0]',          \n",
      "                                                                     'multiply_3[0][0]']          \n",
      "                                                                                                  \n",
      " target_X (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " merged (Concatenate)        (None, 129)                  0         ['add_1[0][0]',               \n",
      "                                                                     'target_X[0][0]']            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 1024)                 133120    ['merged[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 2, 2, 256)            0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 2, 2, 256)            590080    ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 4, 4, 256)            0         ['conv2d_20[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 4, 4, 128)            295040    ['up_sampling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSamplin  (None, 8, 8, 128)            0         ['conv2d_21[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 128)            147584    ['up_sampling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_22[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_23[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 32, 32, 64)           36928     ['up_sampling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampli  (None, 64, 64, 64)           0         ['conv2d_24[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 32)           18464     ['up_sampling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 512)                  524800    ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampli  (None, 128, 128, 32)         0         ['conv2d_25[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 216)                  110808    ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 128, 128, 16)         4624      ['up_sampling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 128)                  27776     ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 128, 128, 8)          1160      ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 32)                   4128      ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " last_conv2d (Conv2D)        (None, 128, 128, 6)          438       ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " touch_values (Dense)        (None, 8)                    264       ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2770766 (10.57 MB)\n",
      "Trainable params: 2770766 (10.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_layer = Input(shape=(None,128,128,4), name=\"image_observation\") \n",
    "touch_layer = Input(shape=(None,9), name=\"touch_observation\") \n",
    "target_X_layer = Input(shape=(1,), name = 'target_X')\n",
    "img_coef_layer = Input(shape=(128,), name = 'image_coef')\n",
    "touch_coef_layer = Input(shape=(128,), name = 'touch_coef')\n",
    "\n",
    "encoder_touch_sizes = [64,64,128,128,256]\n",
    "\n",
    "touch_encoder = TimeDistributed(Dense(32, activation = 'relu'))(touch_layer)\n",
    "for channel_size in encoder_touch_sizes:\n",
    "    touch_encoder = TimeDistributed(Dense(channel_size, activation = 'relu'))(touch_encoder)\n",
    "\n",
    "touch_representations = TimeDistributed(Dense(128, activation='relu'))(touch_encoder) #128\n",
    "touch_representation = GlobalAveragePooling1D()(touch_representations) \n",
    "\n",
    "multiplied_touch = Multiply()([touch_representation,touch_coef_layer])\n",
    "\n",
    "###################################################\n",
    "\n",
    "encoder_img_sizes = [64,64,128,128,256]\n",
    "\n",
    "image_encoder = TimeDistributed(Conv2D(32,(3,3),padding='same',activation='relu'))(image_layer)\n",
    "image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "for channel_size in encoder_img_sizes:\n",
    "    image_encoder = TimeDistributed(Conv2D(channel_size,(3,3),padding='same',activation='relu'))(image_encoder)\n",
    "    image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "\n",
    "image_flatten = TimeDistributed(Flatten())(image_encoder)\n",
    "img_representations = TimeDistributed(Dense(128, activation='relu'))(image_flatten)\n",
    "img_representation = GlobalAveragePooling1D()(img_representations) \n",
    "\n",
    "multiplied_img = Multiply()([img_representation,img_coef_layer])\n",
    "\n",
    "general_representation = Add()([multiplied_touch,multiplied_img])\n",
    "\n",
    "merged_layer = Concatenate(axis=-1, name='merged')([general_representation,target_X_layer])\n",
    "\n",
    "decoder_representation = Dense(1024, activation='relu') (merged_layer)\n",
    "\n",
    "\" =============== Image Decoder =============== \"\n",
    "decoder_img = Reshape([2,2,256])(decoder_representation)\n",
    "decoder_img_sizes = [256,128,128,64,64,32]\n",
    "\n",
    "for channel_size in decoder_img_sizes:\n",
    "    decoder_img = Conv2D(channel_size, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "    decoder_img = UpSampling2D((2, 2))(decoder_img)\n",
    "\n",
    "img_output = Conv2D(16, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "img_output = Conv2D(8, (3,3), padding='same', activation='relu')(img_output)\n",
    "img_output = Conv2D(6, (3,3), padding='same', activation='sigmoid', name = \"last_conv2d\")(img_output)\n",
    "\" =============== Image Decoder =============== \"\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "decoder_touch = Dense(512, activation='relu')(decoder_representation)\n",
    "decoder_touch = Dense(216, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(128, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(32, activation='relu')(decoder_touch)\n",
    "touch_output = Dense(8, activation='sigmoid', name=\"touch_values\")(decoder_touch)\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "\n",
    "model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],[img_output, touch_output])\n",
    "latent_model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],general_representation)\n",
    "model.summary()\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initial_lr = 1e-4  \n",
    "# lowered_lr = 1e-5 \n",
    "\n",
    "# # Use this schedule in the optimizer\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer= Adam(learning_rate = 1e-4),\n",
    "    loss={\n",
    "        'last_conv2d': custom_loss,  \n",
    "        'touch_values': 'mse',  \n",
    "    },\n",
    "    loss_weights={\n",
    "        'last_conv2d': 1,  \n",
    "        'touch_values': 0.01, \n",
    "    },\n",
    "    metrics={  # Add accuracy tracking\n",
    "        'touch_values': ['mae'],  # Mean Absolute Error for touch values\n",
    "    }  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"Epochs_V9\", exist_ok=True)\n",
    "\n",
    "loss_checkpoint = 1000\n",
    "plot_checkpoint = 1000\n",
    "validation_checkpoint = 1000\n",
    "validation_error = 9999999\n",
    "validation_step = -1\n",
    "max_training_step = 200000\n",
    "t_inp = 10\n",
    "data_size = 55\n",
    "n_test = 10\n",
    "\n",
    "dataset = ['image','touch']\n",
    "\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})\n",
    "\n",
    "real_output = []\n",
    "predict_output = []\n",
    "touch_value_idx = 2\n",
    "loss_history = [] \n",
    "\n",
    "for step in range(max_training_step):\n",
    "    inp, out, _, _, coef = get_train_sample()\n",
    "    #val_data, val_labels, _, _ = get_valid_sample()\n",
    "    history = model.fit(inp, out, verbose=0) \n",
    "    loss_history.append(history.history['loss'][0])  \n",
    "\n",
    "    if step % loss_checkpoint == 0 and step!= 0:\n",
    "        path = f\"Epochs_V9/Epoch{step}\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Save model using pickle\n",
    "        model.save(os.path.join(path, \"model.keras\"))\n",
    "\n",
    "        # Save loss history\n",
    "        with open(os.path.join(path, \"loss_history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(loss_history, f)\n",
    "\n",
    "        for test in range(n_test):\n",
    "            step_predictions = []\n",
    "            step_real_values = []\n",
    "            step_absolute_errors_images = []\n",
    "            step_squared_errors_images = []\n",
    "            step_absolute_errors_touch = []\n",
    "            step_squared_errors_touch = []\n",
    "\n",
    "\n",
    "            test_inp, test_out, x, times = get_test_sample(test, t_inp, data_size)\n",
    "\n",
    "\n",
    "            for i in range(t_inp+1, data_size-1):\n",
    "                inp_copy = test_inp.copy() \n",
    "                inp_copy[2] = np.array([[times[i]]])\n",
    "                pred = model.predict_on_batch(inp_copy)\n",
    "\n",
    "                step_predictions.append(pred)\n",
    "                step_real_values.append(test_out[i])\n",
    "\n",
    "\n",
    "                pred_images = np.array(pred[0])\n",
    "                pred_touch_values = np.array(pred[1])  \n",
    "\n",
    "                out_images = np.array(test_out[i][0])  \n",
    "                out_touch_values = np.array(test_out[i][1])  \n",
    "            \n",
    "                step_absolute_errors_images.append(np.abs(out_images - pred_images))  \n",
    "                step_squared_errors_images.append((out_images - pred_images) ** 2) \n",
    "\n",
    "                step_absolute_errors_touch.append(np.abs(out_touch_values - pred_touch_values)) \n",
    "                step_squared_errors_touch.append((out_touch_values - pred_touch_values) ** 2) \n",
    "\n",
    "\n",
    "            del inp_copy, pred\n",
    "    \n",
    "            with open(os.path.join(path, f\"predictions_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_predictions, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"real_values_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_real_values, f)\n",
    "    \n",
    "\n",
    "            with open(os.path.join(path, f\"absolute_errors_touch_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_absolute_errors_touch, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"squared_errors_touch_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_squared_errors_touch, f)\n",
    "\n",
    "                \n",
    "            with open(os.path.join(path, f\"absolute_errors_images_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_absolute_errors_images, f)\n",
    "\n",
    "            with open(os.path.join(path, f\"squared_errors_images_{test}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(step_squared_errors_images, f)\n",
    "\n",
    "            step_predictions.clear()\n",
    "            step_real_values.clear()\n",
    "            step_absolute_errors_images.clear()\n",
    "            step_squared_errors_images.clear()\n",
    "            step_absolute_errors_touch.clear()\n",
    "            step_squared_errors_touch.clear()\n",
    "            gc.collect()\n",
    "\n",
    "    if step % 10000 == 0 and step != 0:\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
