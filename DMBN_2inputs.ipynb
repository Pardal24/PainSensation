{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikop\\AppData\\Local\\Temp\\ipykernel_29604\\701048593.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display as html_width\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from keras.layers import Add,Multiply,Softmax,Input,TimeDistributed,Dense,Average,GlobalAveragePooling1D,Concatenate,Lambda,RepeatVector, Conv2D,ConvLSTM2D, MaxPooling2D,BatchNormalization,Flatten,Reshape,UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "html_width(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import psutil\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]  # Adjust as needed\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n",
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 15 14 47 28 22  0 11 12 33 29 45 24 26 31  2 25 39  6 30 18 20 23 41\n",
      " 13  4 27 38 37  7  9 48 36 40  1 17 21  5 42 19 35 16 34  8 46  3 44 32\n",
      " 10]\n",
      "Remaining train_p: [12, 45, 24, 26, 31, 2, 25, 39, 6, 30, 18, 20, 23, 41, 13, 4, 27, 38, 37, 7, 9, 48, 36, 40, 1, 17, 21, 5, 42, 19, 35, 16, 34, 8, 46, 3, 44, 32, 10]\n",
      "test_p: [43, 15, 14, 47, 28, 22, 0, 11, 33, 29]\n"
     ]
    }
   ],
   "source": [
    "obs_min = 4\n",
    "obs_max = 8\n",
    "train_N = 49\n",
    "train_p = np.random.permutation(49)\n",
    "j = 0\n",
    "x = 0\n",
    "test_p = []\n",
    "print(train_p)\n",
    "\n",
    "train_p_copy = train_p.copy()\n",
    "\n",
    "for i in train_p_copy:\n",
    "    if i < 25 and j < 5:\n",
    "        test_p.append(i)\n",
    "        j += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "    if i > 25 and x < 5:\n",
    "        test_p.append(i)\n",
    "        x += 1\n",
    "        train_p = [item for item in train_p if item != i]  # Remove from train_p\n",
    "\n",
    "print(\"Remaining train_p:\", train_p)\n",
    "print(\"test_p:\", test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Modality Blending Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try now with only 2 inputs (img and touch)\n",
    "\n",
    "rndm coef like default\n",
    "\n",
    "if more worried about the image using a coef for the image >0.2\n",
    "\n",
    "For testing give 1 to img coef for only giving image\n",
    "\n",
    "For easy test give coef of 0.5 for only two inputs\n",
    "\n",
    "always add rnd samples from 0 zone and touch zone if necessary\n",
    "\n",
    "plot the touch.txt for each data folder\n",
    "\n",
    "use the weights from default\n",
    "\n",
    "Add noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coef > 2\n",
    "noise\n",
    "plot for only one sensor\n",
    "reduce/increase more the weight for the touch sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################### GET TRAIN SAMPLES ############################################################################\n",
    "\n",
    "def get_train_sample(coef = -1):\n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = train_p[np.random.randint(0, 39)]\n",
    "    \n",
    "    if coef == -1:\n",
    "         coef = np.random.uniform(0.2, 1.0)\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data3/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    # Identify zero and nonzero rows\n",
    "    zero_rows = np.where(np.all(pose == 0, axis=1))[0]\n",
    "    nonzero_rows = np.where(np.any(pose != 0, axis=1))[0]\n",
    "    \n",
    "    if len(nonzero_rows) == 0 or len(zero_rows) == 0:\n",
    "        raise ValueError(\"Dataset does not contain both zero and nonzero rows.\")\n",
    "\n",
    "    # Ensure at least one sample from each\n",
    "    num_from_each = min(n // 2, len(nonzero_rows), len(zero_rows))\n",
    "    selected_nonzero = np.random.choice(nonzero_rows, num_from_each, replace=False)\n",
    "    selected_zero = np.random.choice(zero_rows, num_from_each, replace=False)\n",
    "\n",
    "    remaining_samples = n - 2 * num_from_each\n",
    "    if remaining_samples > 0:\n",
    "        additional_samples = np.random.choice(time_len, remaining_samples, replace=False)\n",
    "    else:\n",
    "        additional_samples = np.array([], dtype=int)\n",
    "    selected_indices = np.concatenate((selected_nonzero, selected_zero, additional_samples))\n",
    "    np.random.shuffle(selected_indices)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data3/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, i, :, :, 1:] = image_resized / 255.\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = pose[idx] / 255\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    t_img = mpimg.imread('Data3/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize / 255.\n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1], coef\n",
    "\n",
    "\n",
    "\n",
    "######################################################################### GET TEST SAMPLES ############################################################################\n",
    "\n",
    "\n",
    "def get_valid_sample():\n",
    "    n = np.random.randint(obs_min, obs_max) + 1\n",
    "    d = train_p[np.random.randint(0, 9)]\n",
    "\n",
    "    coef = 1\n",
    "    \n",
    "    img_coef = np.ones((1, 128)) * coef\n",
    "    touch_coef = np.ones((1, 128)) * (1 - coef)\n",
    "    \n",
    "    observation = np.zeros((1, n, 128, 128, 4)) \n",
    "    observation_touch = np.zeros((1, n, 9)) \n",
    "    target_X = np.zeros((1, 1))\n",
    "    target_Y = np.zeros((1, 128, 128, 6))\n",
    "    #target_Y_touch = np.zeros((1, 16))\n",
    "    target_Y_touch = np.zeros((1, 8))\n",
    "    \n",
    "    pose = np.loadtxt('Data3/%d/touch_data.txt' % d)\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0, 1, time_len)\n",
    "\n",
    "    # Identify zero and nonzero rows\n",
    "    zero_rows = np.where(np.all(pose == 0, axis=1))[0]\n",
    "    nonzero_rows = np.where(np.any(pose != 0, axis=1))[0]\n",
    "    \n",
    "    if len(nonzero_rows) == 0 or len(zero_rows) == 0:\n",
    "        raise ValueError(\"Dataset does not contain both zero and nonzero rows.\")\n",
    "\n",
    "    # Ensure at least one sample from each\n",
    "    num_from_each = min(n // 2, len(nonzero_rows), len(zero_rows))\n",
    "    selected_nonzero = np.random.choice(nonzero_rows, num_from_each, replace=False)\n",
    "    selected_zero = np.random.choice(zero_rows, num_from_each, replace=False)\n",
    "\n",
    "    remaining_samples = n - 2 * num_from_each\n",
    "    if remaining_samples > 0:\n",
    "        additional_samples = np.random.choice(time_len, remaining_samples, replace=False)\n",
    "    else:\n",
    "        additional_samples = np.array([], dtype=int)\n",
    "    selected_indices = np.concatenate((selected_nonzero, selected_zero, additional_samples))\n",
    "    np.random.shuffle(selected_indices)\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        if i < n -1:\n",
    "            observation[0, i, :, :, 0] = np.ones((128, 128)) * times[idx]\n",
    "            image = mpimg.imread('Data3/%d/frame_%d.jpeg' % (d, idx))\n",
    "            image_resized = cv2.resize(image, (128, 128))\n",
    "            observation[0, i, :, :, 1:] = image_resized / 255.\n",
    "\n",
    "            observation_touch[0, i, 0] = times[idx]\n",
    "            observation_touch[0, i, 1:9] = pose[idx] / 255\n",
    "\n",
    "    target_X[0, 0] = times[selected_indices[-1]]\n",
    "    t_img = mpimg.imread('Data3/%d/frame_%d.jpeg' % (d, selected_indices[-1]))\n",
    "    t_img_resize = cv2.resize(t_img, (128, 128))\n",
    "    target_Y[0, :, :, :3] = t_img_resize / 255.\n",
    "    target_Y_touch[0, :8] = pose[selected_indices[-1]] / 255\n",
    "\n",
    "    return [observation, observation_touch, target_X, img_coef, touch_coef], [target_Y, target_Y_touch], d, selected_indices[-1]\n",
    "\n",
    "#inp, out, _, _ = get_train_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(y_true, y_predicted):\n",
    "    mean, log_sigma = tf.split(y_predicted, 2, axis=-1)\n",
    "    y_true_value, temp =tf.split(y_true,2,axis=-1)\n",
    "    #mean = tf.nn.relu(mean)\n",
    "    sigma = tf.nn.softplus(log_sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(loc=mean, scale_diag=sigma)\n",
    "    loss = -tf.reduce_mean(dist.log_prob(y_true_value))\n",
    "    return loss\n",
    "\n",
    "\n",
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, coef, step):\n",
    "        super().__init__()\n",
    "        self.coef = coef \n",
    "        self.step = step \n",
    "        self.best_val_acc = float('inf')  # Initialize with a large value\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "        logs = logs or {}  # Ensure logs is not None\n",
    "        process = psutil.Process(os.getpid())  \n",
    "        memory_usage = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "        train_acc = logs.get(\"touch_values_mae\", \"N/A\")  # Replace 'accuracy' with the correct metric\n",
    "        val_acc = logs.get(\"val_touch_values_mae\", \"N/A\")  \n",
    "\n",
    "        if val_acc != \"N/A\" and train_acc != \"N/A\":\n",
    "            # Save the model only if the validation MAE improves\n",
    "            if val_acc < self.best_val_acc:\n",
    "                self.best_val_acc = val_acc  # Update the best validation accuracy\n",
    "                if os.path.exists(\"Info_model.txt\"):\n",
    "                    os.remove(\"Info_model.txt\")\n",
    "                with open(\"Info_model.txt\", \"a\") as f:\n",
    "                    f.write(f\"Step: {self.step} \\n Coef = {self.coef} \\n\")\n",
    "                self.model.save('my_model.keras', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_observation (InputLa  [(None, None, 128, 128, 4)   0         []                            \n",
      " yer)                        ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDi  (None, None, 128, 128, 32)   1184      ['image_observation[0][0]']   \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDi  (None, None, 64, 64, 32)     0         ['time_distributed_7[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDi  (None, None, 64, 64, 64)     18496     ['time_distributed_8[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeD  (None, None, 32, 32, 64)     0         ['time_distributed_9[0][0]']  \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeD  (None, None, 32, 32, 64)     36928     ['time_distributed_10[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeD  (None, None, 16, 16, 64)     0         ['time_distributed_11[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " touch_observation (InputLa  [(None, None, 9)]            0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeD  (None, None, 16, 16, 128)    73856     ['time_distributed_12[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 32)             320       ['touch_observation[0][0]']   \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeD  (None, None, 8, 8, 128)      0         ['time_distributed_13[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, None, 64)             2112      ['time_distributed[0][0]']    \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_15 (TimeD  (None, None, 8, 8, 128)      147584    ['time_distributed_14[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, None, 64)             4160      ['time_distributed_1[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_16 (TimeD  (None, None, 4, 4, 128)      0         ['time_distributed_15[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDi  (None, None, 128)            8320      ['time_distributed_2[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_17 (TimeD  (None, None, 4, 4, 256)      295168    ['time_distributed_16[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDi  (None, None, 128)            16512     ['time_distributed_3[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_18 (TimeD  (None, None, 2, 2, 256)      0         ['time_distributed_17[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDi  (None, None, 256)            33024     ['time_distributed_4[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_19 (TimeD  (None, None, 1024)           0         ['time_distributed_18[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDi  (None, None, 128)            32896     ['time_distributed_5[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_20 (TimeD  (None, None, 128)            131200    ['time_distributed_19[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['time_distributed_6[0][0]']  \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " touch_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['time_distributed_20[0][0]'] \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " image_coef (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 128)                  0         ['global_average_pooling1d[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'touch_coef[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 128)                  0         ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'image_coef[0][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128)                  0         ['multiply[0][0]',            \n",
      "                                                                     'multiply_1[0][0]']          \n",
      "                                                                                                  \n",
      " target_X (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " merged (Concatenate)        (None, 129)                  0         ['add[0][0]',                 \n",
      "                                                                     'target_X[0][0]']            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1024)                 133120    ['merged[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 2, 2, 256)            0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 2, 2, 256)            590080    ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 4, 4, 256)            0         ['conv2d_6[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 128)            295040    ['up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 8, 8, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)            147584    ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_8[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)           73792     ['up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 64)           36928     ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_10[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 32)           18464     ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 512)                  524800    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 128, 128, 32)         0         ['conv2d_11[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 216)                  110808    ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 16)         4624      ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 128)                  27776     ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 8)          1160      ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 32)                   4128      ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " last_conv2d (Conv2D)        (None, 128, 128, 6)          438       ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " touch_values (Dense)        (None, 8)                    264       ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2770766 (10.57 MB)\n",
      "Trainable params: 2770766 (10.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_layer = Input(shape=(None,128,128,4), name=\"image_observation\") \n",
    "touch_layer = Input(shape=(None,9), name=\"touch_observation\") \n",
    "#class_layer = Input(shape=(None,2), name=\"class_observation\") \n",
    "target_X_layer = Input(shape=(1,), name = 'target_X')\n",
    "img_coef_layer = Input(shape=(128,), name = 'image_coef')\n",
    "touch_coef_layer = Input(shape=(128,), name = 'touch_coef')\n",
    "#class_coef_layer = Input(shape=(128,), name = 'class_coef')\n",
    "\n",
    "encoder_touch_sizes = [64,64,128,128,256]\n",
    "\n",
    "touch_encoder = TimeDistributed(Dense(32, activation = 'relu'))(touch_layer)\n",
    "for channel_size in encoder_touch_sizes:\n",
    "    touch_encoder = TimeDistributed(Dense(channel_size, activation = 'relu'))(touch_encoder)\n",
    "\n",
    "touch_representations = TimeDistributed(Dense(128, activation='relu'))(touch_encoder) #128\n",
    "touch_representation = GlobalAveragePooling1D()(touch_representations) \n",
    "\n",
    "multiplied_touch = Multiply()([touch_representation,touch_coef_layer])\n",
    "\n",
    "###################################################\n",
    "\n",
    "encoder_img_sizes = [64,64,128,128,256]\n",
    "\n",
    "image_encoder = TimeDistributed(Conv2D(32,(3,3),padding='same',activation='relu'))(image_layer)\n",
    "image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "for channel_size in encoder_img_sizes:\n",
    "    image_encoder = TimeDistributed(Conv2D(channel_size,(3,3),padding='same',activation='relu'))(image_encoder)\n",
    "    image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "\n",
    "image_flatten = TimeDistributed(Flatten())(image_encoder)\n",
    "img_representations = TimeDistributed(Dense(128, activation='relu'))(image_flatten)\n",
    "img_representation = GlobalAveragePooling1D()(img_representations) \n",
    "\n",
    "multiplied_img = Multiply()([img_representation,img_coef_layer])\n",
    "\n",
    "general_representation = Add()([multiplied_touch,multiplied_img])\n",
    "\n",
    "merged_layer = Concatenate(axis=-1, name='merged')([general_representation,target_X_layer])\n",
    "\n",
    "decoder_representation = Dense(1024, activation='relu') (merged_layer)\n",
    "\n",
    "\" =============== Image Decoder =============== \"\n",
    "decoder_img = Reshape([2,2,256])(decoder_representation)\n",
    "decoder_img_sizes = [256,128,128,64,64,32]\n",
    "\n",
    "for channel_size in decoder_img_sizes:\n",
    "    decoder_img = Conv2D(channel_size, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "    decoder_img = UpSampling2D((2, 2))(decoder_img)\n",
    "\n",
    "img_output = Conv2D(16, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "img_output = Conv2D(8, (3,3), padding='same', activation='relu')(img_output)\n",
    "img_output = Conv2D(6, (3,3), padding='same', activation='sigmoid', name = \"last_conv2d\")(img_output)\n",
    "\" =============== Image Decoder =============== \"\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "decoder_touch = Dense(512, activation='relu')(decoder_representation)\n",
    "decoder_touch = Dense(216, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(128, activation='relu')(decoder_touch)\n",
    "decoder_touch = Dense(32, activation='relu')(decoder_touch)\n",
    "touch_output = Dense(8, activation='sigmoid', name=\"touch_values\")(decoder_touch)\n",
    "\n",
    "\" =============== Touch Decoder =============== \"\n",
    "\n",
    "model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],[img_output, touch_output])\n",
    "latent_model = Model([image_layer, touch_layer, target_X_layer, img_coef_layer, touch_coef_layer],general_representation)\n",
    "model.summary()\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer= Adam(lr=1e-4),\n",
    "    loss={\n",
    "        'last_conv2d': custom_loss,  \n",
    "        'touch_values': 'mse',  \n",
    "    },\n",
    "    loss_weights={\n",
    "        'last_conv2d': 1,  \n",
    "        'touch_values': 0.01, \n",
    "    },\n",
    "    metrics={  # Add accuracy tracking\n",
    "        'touch_values': ['mae'],  # Mean Absolute Error for touch values\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m inp, out, _, _, coef \u001b[38;5;241m=\u001b[39m get_train_sample()\n\u001b[0;32m     82\u001b[0m val_data, val_labels, _, _ \u001b[38;5;241m=\u001b[39m get_valid_sample()\n\u001b[1;32m---> 83\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mMemoryCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Capture training history\u001b[39;00m\n\u001b[0;32m     84\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Store loss\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m plot_checkpoint \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\kikop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(\"Plots/Touch_Values\", exist_ok=True)\n",
    "os.makedirs(\"Plots/Loss\", exist_ok=True)\n",
    "\n",
    "loss_checkpoint = 1000\n",
    "plot_checkpoint = 1000\n",
    "validation_checkpoint = 1000\n",
    "validation_error = 9999999\n",
    "validation_step = -1\n",
    "max_training_step = 1000000\n",
    "\n",
    "dataset = ['image','touch']\n",
    "\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind': float_formatter})\n",
    "\n",
    "real_output = []\n",
    "predict_output = []\n",
    "touch_value_idx = 2\n",
    "loss_history = [] \n",
    "\n",
    "for step in range(max_training_step):\n",
    "    inp, out, _, _, coef = get_train_sample()\n",
    "    val_data, val_labels, _, _ = get_valid_sample()\n",
    "    history = model.fit(inp, out, verbose=0, validation_data=(val_data, val_labels), callbacks=[MemoryCallback(coef, step)]) \n",
    "    loss_history.append(history.history['loss'][0])  \n",
    "\n",
    "    if step % plot_checkpoint == 0:\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        inp, out, _, _, _ = get_train_sample()\n",
    "        \n",
    "        # Predict touch values\n",
    "        pred_touch = model.predict(inp)[1][0]\n",
    "        real_touch = out[1][0] \n",
    "\n",
    "        # Store full sequences (instead of single index)\n",
    "        real_output.append(real_touch)  \n",
    "        predict_output.append(pred_touch)\n",
    "\n",
    "        # Convert lists to NumPy arrays for easier plotting\n",
    "        real_output_np = np.array(real_output)\n",
    "        predict_output_np = np.array(predict_output)\n",
    "\n",
    "        # Plot touch waveform for last epoch\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(real_output_np[-1], label=\"True Touch Values\", color='blue')  # Last epoch real values\n",
    "        plt.plot(predict_output_np[-1], label=\"Predicted Touch Values\", color='red', linestyle='--')  # Last epoch predictions\n",
    "\n",
    "        plt.xlabel(\"Integrated Sensors\")\n",
    "        plt.ylabel(\"Touch Value\")\n",
    "        plt.title(\"Touch Sensor Predictions (Waveform)\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot\n",
    "        touch_plot_path = f\"Plots/Touch_Values/touch_plot_step_{step}.png\"\n",
    "        plt.savefig(touch_plot_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # Plot loss trend\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(loss_history, label=\"Loss\", color='green')\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss Trend\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the loss plot\n",
    "        loss_plot_path = f\"Plots/Loss/loss_plot_step_{step}.png\"\n",
    "        plt.savefig(loss_plot_path)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
