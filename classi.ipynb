{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: test_29\n",
      "Processing dataset: test_16\n",
      "Processing dataset: test_38\n",
      "Processing dataset: test_37\n",
      "Processing dataset: test_41\n",
      "Processing dataset: test_15\n",
      "Processing dataset: test_18\n",
      "Processing dataset: test_25\n",
      "Processing dataset: test_31\n",
      "Processing dataset: test_23\n",
      "Processing dataset: test_11\n",
      "Processing dataset: test_8\n",
      "Processing dataset: test_14\n",
      "Processing dataset: test_28\n",
      "Processing dataset: test_33\n",
      "Processing dataset: test_12\n",
      "Processing dataset: test_5\n",
      "Processing dataset: test_19\n",
      "Processing dataset: test_6\n",
      "Processing dataset: test_35\n",
      "Processing dataset: test_21\n",
      "Processing dataset: test_27\n",
      "Processing dataset: test_3\n",
      "Processing dataset: test_7\n",
      "Processing dataset: test_44\n",
      "Processing dataset: test_36\n",
      "Processing dataset: test_34\n",
      "Processing dataset: test_1\n",
      "Processing dataset: test_17\n",
      "Processing dataset: test_42\n",
      "Processing dataset: test_20\n",
      "Processing dataset: test_10\n",
      "Processing dataset: test_40\n",
      "Processing dataset: test_24\n",
      "Processing dataset: test_43\n",
      "Processing dataset: test_4\n",
      "Processing dataset: test_22\n",
      "Processing dataset: test_2\n",
      "Processing dataset: test_30\n",
      "Processing dataset: test_39\n",
      "Processing dataset: test_13\n",
      "Processing dataset: test_26\n",
      "Processing dataset: test_9\n",
      "Processing dataset: test_32\n",
      "Predicted: TOUCH for test_32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "touch_values = []\n",
    "classi = []\n",
    "\n",
    "# === 1. Parse touch_prediction.txt ===\n",
    "def load_touch_predictions(filepath):\n",
    "    \"\"\"Loads the touch prediction file and extracts the arrays.\"\"\"\n",
    "    values = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            # Remove \"Step x:\" prefix and convert to list of floats\n",
    "            clean_line = line.split(':', 1)[-1].strip()\n",
    "            arr = eval(clean_line)  # safely parse the list\n",
    "            values.append(arr)\n",
    "    return np.array(values)  # shape (T, 8)\n",
    "\n",
    "# === 2. Main code to loop through datasets ===\n",
    "results_dir = \"Results\"  # Path to the directory with multiple datasets\n",
    "for d in os.listdir(results_dir):\n",
    "    # Construct full path to touch predictions and labels for each dataset\n",
    "    touch_file = os.path.join(results_dir, d, \"touch_predictions.txt\")\n",
    "    label_file = os.path.join(results_dir, d, \"touch_type.txt\")\n",
    "    \n",
    "    if os.path.exists(touch_file) and os.path.exists(label_file):\n",
    "        print(f\"Processing dataset: {d}\")\n",
    "\n",
    "        # Load touch prediction arrays (shape = (T, 8))\n",
    "        X_seq = load_touch_predictions(touch_file)\n",
    "        #print (X_seq)\n",
    "        X_flat = X_seq.flatten()  # Flatten to (T*8,)\n",
    "        \n",
    "        # Load the label (assumed to be one per dataset)\n",
    "        with open(label_file, \"r\") as f:\n",
    "            y_raw = f.read().strip()\n",
    "        \n",
    "        touch_values.append(X_flat)\n",
    "        classi.append(y_raw)\n",
    "    else:\n",
    "        print(f\"Skipping dataset {d} (missing files).\")\n",
    "\n",
    "# Encode the label (Pain/Touch -> 0/1)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(classi)\n",
    "\n",
    "# Train classifier (SVM in this case)\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(touch_values, y_encoded)  # Train with one sample per dataset\n",
    "\n",
    "# Predict\n",
    "pred = clf.predict([X_flat])\n",
    "print(f\"Predicted: {le.inverse_transform(pred)[0]} for {d}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: PAIN\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict([touch_values[0]])\n",
    "print(f\"Predicted: {le.inverse_transform(pred)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         1.         1.         0.88888889 1.        ]\n",
      "Mean cross-validation score: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(clf, touch_values, y_encoded, cv=5)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and label encoder saved to 'svm_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"svm_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(clf, model_file)\n",
    "    pickle.dump(le, model_file)  # Save the label encoder as well\n",
    "\n",
    "print(\"Model and label encoder saved to 'svm_model.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
